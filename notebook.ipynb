{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "import os\n",
    "\n",
    "# third-party imports\n",
    "import mlflow\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRACKING_URI = 'http://127.0.0.1:8080'\n",
    "EXPERIMENT_NAME = 'Housing_Models'\n",
    "RUN_NAME = 'housing_gb_test'\n",
    "ARTIFACT_PATH = 'gb_housing'\n",
    "REGISTERED_MODEL_NAME = 'housing_prod'\n",
    "MODEL_ALIAS = 'prod'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load California housing dataset\n",
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "# Prepare target variable by converting the continuous target into classes (classification task)\n",
    "# We'll divide the target into 3 classes (low, medium, high housing prices)\n",
    "y = np.digitize(data.target, bins=[1.5, 3.0])\n",
    "\n",
    "# Standardize features (helps in gradient boosting)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data.data)\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create Pandas DataFrames for logging\n",
    "train_df = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "train_df['label'] = y_train\n",
    "\n",
    "eval_df = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "eval_df['label'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 16:21:45 INFO mlflow.tracking.fluent: Experiment with name 'Housing_Models' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "# Sets the URI of the MLflow Tracking Server\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "\n",
    "# Sets the current active experiment and returns the Experiment metadata\n",
    "experiment = mlflow.set_experiment(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/24 16:21:45 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2024/09/24 16:21:45 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "/home/parente/.virtualenvs/mlflow-tutorial/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/09/24 16:21:55 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/09/24 16:22:06 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/09/24 16:22:16 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/09/24 16:22:26 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/09/24 16:22:36 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "2024/09/24 16:22:46 WARNING mlflow.system_metrics.metrics.gpu_monitor: Encountered error Unknown Error when trying to collect GPU metrics.\n",
      "/home/parente/.virtualenvs/mlflow-tutorial/lib/python3.10/site-packages/mlflow/types/utils.py:407: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  warnings.warn(\n",
      "2024/09/24 16:22:55 INFO mlflow.models.evaluation.default_evaluator: The evaluation dataset is inferred as multiclass dataset, number of classes is inferred as 3. If this is incorrect, please specify the `label_list` parameter in `evaluator_config`.\n",
      "2024/09/24 16:22:55 INFO mlflow.models.evaluation.default_evaluator: Testing metrics on first row...\n",
      "2024/09/24 16:22:55 WARNING mlflow.models.evaluation.default_evaluator: SHAP or matplotlib package is not installed, so model explainability insights will not be logged.\n",
      "2024/09/24 16:22:55 INFO mlflow.tracking._tracking_service.client: üèÉ View run housing_gb_test at: http://127.0.0.1:8080/#/experiments/942542597364770131/runs/4f9bbef2dd7a414cb3f6bb790e913b59.\n",
      "2024/09/24 16:22:55 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://127.0.0.1:8080/#/experiments/942542597364770131.\n",
      "2024/09/24 16:22:55 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/09/24 16:22:55 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=RUN_NAME, log_system_metrics=True) as run:\n",
    "\n",
    "    # Log the training dataset\n",
    "    mlflow.log_input(mlflow.data.from_pandas(train_df), context='training')\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': 500,\n",
    "        'learning_rate': 0.1,\n",
    "        'max_depth': 5\n",
    "    }\n",
    "\n",
    "    # Initialize the Gradient Boosting Classifier\n",
    "    clf = GradientBoostingClassifier(**params)\n",
    "    \n",
    "    # Learn the digits on the train subset\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Predict the value of the digit on the test subset\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Add predictions to the evaluation DataFrame\n",
    "    eval_df['predictions'] = y_pred\n",
    "\n",
    "    # Create the PandasDataset for use in mlflow evaluate\n",
    "    pd_dataset = mlflow.data.from_pandas(eval_df, predictions='predictions', targets='label')\n",
    "\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=clf, input_example=X_test, artifact_path=ARTIFACT_PATH\n",
    "    )\n",
    "\n",
    "    # Execute evaluation\n",
    "    mlflow.evaluate(data=pd_dataset, model_type='classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a New Model and Registering the Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to MLFlow Tracking System\n",
    "client = mlflow.MlflowClient(TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the experiment ID\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Filter runs by run name\n",
    "filtered_runs = client.search_runs(\n",
    "    experiment_ids=[experiment_id], \n",
    "    filter_string=f\"tags.mlflow.runName='{RUN_NAME}'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain model_uri\n",
    "run = filtered_runs[0]\n",
    "run_id = run.info.run_id\n",
    "model_uri = f'runs:/{run_id}/{ARTIFACT_PATH}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'housing_prod' already exists. Creating a new version of this model...\n",
      "2024/09/24 16:28:12 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: housing_prod, version 1\n",
      "Created version '1' of model 'housing_prod'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1727206092405, current_stage='None', description='', last_updated_timestamp=1727206092405, name='housing_prod', run_id='4f9bbef2dd7a414cb3f6bb790e913b59', run_link='', source='mlflow-artifacts:/942542597364770131/4f9bbef2dd7a414cb3f6bb790e913b59/artifacts/gb_housing', status='READY', status_message='', tags={}, user_id='', version='1'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a New Model\n",
    "client.create_registered_model(REGISTERED_MODEL_NAME)\n",
    "\n",
    "# Register the model\n",
    "mlflow.register_model(model_uri, REGISTERED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set an Alias to the Registered Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the registered model details\n",
    "registered_model = client.get_registered_model(REGISTERED_MODEL_NAME)\n",
    "\n",
    "# Get the latest model version\n",
    "latest_version = max(registered_model.latest_versions, key=lambda x: x.version)\n",
    "\n",
    "# Set the alias for the latest model version\n",
    "client.set_registered_model_alias(\n",
    "        alias=MODEL_ALIAS,\n",
    "        name=REGISTERED_MODEL_NAME,\n",
    "        version=latest_version.version,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
